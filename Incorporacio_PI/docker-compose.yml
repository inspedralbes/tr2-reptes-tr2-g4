services:
  rabbitmq:
    image: rabbitmq:3-management
    container_name: pi_rabbitmq
    restart: always
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq/
    networks:
      - app-network
    environment:
      - RABBITMQ_DEFAULT_USER=user
      - RABBITMQ_DEFAULT_PASS=1234
      - RABBITMQ_ERLANG_COOKIE=secret_cookie_12345 # Fix for permission issues
    healthcheck:
      test: [ "CMD", "rabbitmq-diagnostics", "-q", "check_running" ]
      interval: 15s
      timeout: 15s
      retries: 20
      start_period: 300s

  backend:
    build: ./backend
    container_name: pi_backend
    ports:
      - "4001:4000"
    volumes:
      - ./backend:/app
      - /app/node_modules
    env_file:
      - ./backend/.env
    command: npm start
    networks:
      - app-network
    depends_on:
      rabbitmq:
        condition: service_healthy

  worker:
    build: ./backend
    container_name: pi_worker
    volumes:
      - ./backend:/app
      - /app/node_modules
    env_file:
      - ./backend/.env
    command: node worker.js
    networks:
      - app-network
    depends_on:
      rabbitmq:
        condition: service_healthy
      ollama:
        condition: service_healthy

  frontend:
    build: ./frontend
    container_name: pi_frontend
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    depends_on:
      - backend
    command: npm run dev -- --host --port 3000
    networks:
      - app-network

  ollama:
    image: ollama/ollama:latest
    container_name: pi_llm
    ports:
      - "11434:11434"
    volumes:
      - ${PATH_DADES:-./ollama_storage}:/root/.ollama
      - ./backend/models:/root/.ollama/models
    networks:
      - app-network
    environment:
      - MODEL_NAME=${MODEL_NAME:-llama3.2:3b}
    entrypoint: [ "/bin/sh", "-c" ]
    command:
      - |
        ollama serve &
        echo "Esperant que el servidor Ollama estigui actiu..."
        until ollama list > /dev/null 2>&1; do
          sleep 2
        done
        if ollama list | grep -q "$${MODEL_NAME}"; then
          echo "El model $${MODEL_NAME} ja està preparat."
        else
          echo "Model $${MODEL_NAME} no trobat. Iniciant descàrrega..."
          until ollama pull $${MODEL_NAME}; do
            echo "Error en la descàrrega. Reintentant..."
            sleep 5
          done
        fi
        wait
    healthcheck:
      test: [ "CMD-SHELL", "ollama list | grep -q \"$${MODEL_NAME}\"" ]
      interval: 15s
      timeout: 10s
      retries: 40
      start_period: 600s

networks:
  app-network:
    driver: bridge

volumes:
  rabbitmq_data: